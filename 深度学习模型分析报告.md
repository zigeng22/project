# 深度学习模型分析报告

## STAT8003 Time Series Forecasting Course Project
### 香港机场旅客流量预测 - 深度学习部分

---

## 一、项目概述

### 1.1 研究背景
本项目使用深度学习方法对香港机场日客流量进行时间序列预测。本报告聚焦于机器学习/深度学习部分，传统时间序列方法（如SARIMA）由队友完成。

### 1.2 数据集信息
| 项目 | 描述 |
|------|------|
| 训练集 | 1,077天 (2023-01-01 至 2025-12-12) |
| 测试集 | 5天 (2025-12-13 至 2025-12-17) |
| 预测变量 | 每日旅客总数 (Total) |

### 1.3 测试集详情
| 日期 | 星期 | 类型 | 实际客流 |
|------|------|------|----------|
| 2025-12-13 | 周六 | 周末 | 138,454 |
| 2025-12-14 | 周日 | 周末 | 144,818 |
| 2025-12-15 | 周一 | 工作日 | 140,572 |
| 2025-12-16 | 周二 | 工作日 | 124,901 |
| 2025-12-17 | 周三 | 工作日 | 131,212 |

---

## 二、模型选择

本研究选择了3个模型进行对比分析：

| 模型 | 类型 | 选择理由 |
|------|------|----------|
| **LSTM** | 深度学习 | 经典的序列模型，能够捕获长期依赖关系 |
| **GRU** | 深度学习 | LSTM的简化版本，参数更少，训练更快 |
| **XGBoost** | 机器学习 | 作为基准对比，代表传统ML方法的最佳水平 |

---

## 三、特征工程

### 3.1 输入特征（6维）
```
1. Total         - 历史客流量
2. DayOfWeek_sin - 星期的正弦编码
3. DayOfWeek_cos - 星期的余弦编码
4. IsWeekend     - 是否周末（0或1）
5. Month_sin     - 月份的正弦编码
6. Month_cos     - 月份的余弦编码
```

### 3.2 周期性编码说明
使用三角函数编码可以：
- 保持周期性特征的连续性（如周日→周一的过渡）
- 避免模型将星期/月份误解为数值大小关系

公式：
- `DayOfWeek_sin = sin(2π × DayOfWeek / 7)`
- `DayOfWeek_cos = cos(2π × DayOfWeek / 7)`

---

## 四、LSTM模型详解

### 4.1 模型架构
```
┌─────────────────────────────────────────────────────────┐
│  Input: (batch, 30, 6)                                  │
│    ↓                                                    │
│  LSTM Layer 1: 64 hidden units                          │
│    ↓                                                    │
│  Dropout: 0.2                                           │
│    ↓                                                    │
│  LSTM Layer 2: 64 hidden units                          │
│    ↓                                                    │
│  Fully Connected: 64 → 1                                │
│    ↓                                                    │
│  Output: (batch, 1)                                     │
└─────────────────────────────────────────────────────────┘
```

### 4.2 LSTM原理
LSTM（Long Short-Term Memory）是一种特殊的RNN，通过三个门控机制解决梯度消失问题：

| 门控 | 功能 |
|------|------|
| 遗忘门 (Forget Gate) | 决定丢弃哪些旧信息 |
| 输入门 (Input Gate) | 决定存储哪些新信息 |
| 输出门 (Output Gate) | 决定输出什么信息 |

### 4.3 训练配置
| 参数 | 值 |
|------|-----|
| 窗口大小 | 30天 |
| 隐藏层单元数 | 64 |
| LSTM层数 | 2 |
| Dropout | 0.2 |
| 优化器 | Adam |
| 学习率 | 0.001 |
| 批大小 | 32 |
| 早停耐心值 | 15 |
| **总参数量** | **51,777** |

### 4.4 训练过程
- 训练在第93轮后早停
- 最佳验证损失: 0.3187

### 4.5 预测结果
| 日期 | 星期 | 实际值 | 预测值 | 误差 | 误差% |
|------|------|--------|--------|------|-------|
| 12/13 | Sat | 138,454 | 145,585 | -7,131 | -5.2% |
| 12/14 | Sun | 144,818 | 148,369 | -3,551 | -2.5% |
| 12/15 | Mon | 140,572 | 144,286 | -3,714 | -2.6% |
| 12/16 | Tue | 124,901 | 136,064 | -11,163 | -8.9% |
| 12/17 | Wed | 131,212 | 139,815 | -8,603 | -6.6% |

### 4.6 LSTM评估指标
| 指标 | 值 |
|------|-----|
| MAE | 6,833 |
| RMSE | 7,428 |
| **MAPE** | **5.15%** |

---

## 五、GRU模型详解

### 5.1 模型架构
```
┌─────────────────────────────────────────────────────────┐
│  Input: (batch, 30, 6)                                  │
│    ↓                                                    │
│  GRU Layer 1: 64 hidden units                           │
│    ↓                                                    │
│  Dropout: 0.2                                           │
│    ↓                                                    │
│  GRU Layer 2: 64 hidden units                           │
│    ↓                                                    │
│  Fully Connected: 64 → 1                                │
│    ↓                                                    │
│  Output: (batch, 1)                                     │
└─────────────────────────────────────────────────────────┘
```

### 5.2 GRU原理
GRU（Gated Recurrent Unit）是LSTM的简化版本，只有两个门控：

| 门控 | 功能 |
|------|------|
| 重置门 (Reset Gate) | 决定忽略多少过去的信息 |
| 更新门 (Update Gate) | 决定使用多少候选状态 |

### 5.3 GRU vs LSTM对比
| 特性 | LSTM | GRU |
|------|------|-----|
| 门控数量 | 3 | 2 |
| 细胞状态 | 有 | 无 |
| 参数量 | 51,777 | 38,849 |
| 训练速度 | 较慢 | 较快 |
| 参数减少 | - | 25.0% |

### 5.4 训练配置
与LSTM相同，但：
- **总参数量**: **38,849**（比LSTM少25%）
- 训练在第54轮后早停

### 5.5 预测结果
| 日期 | 星期 | 实际值 | 预测值 | 误差 | 误差% |
|------|------|--------|--------|------|-------|
| 12/13 | Sat | 138,454 | 137,143 | +1,311 | +0.9% |
| 12/14 | Sun | 144,818 | 142,455 | +2,363 | +1.6% |
| 12/15 | Mon | 140,572 | 136,328 | +4,244 | +3.0% |
| 12/16 | Tue | 124,901 | 124,926 | -25 | -0.0% |
| 12/17 | Wed | 131,212 | 126,328 | +4,884 | +3.7% |

### 5.6 GRU评估指标
| 指标 | 值 |
|------|-----|
| MAE | 2,565 |
| RMSE | 3,136 |
| **MAPE** | **1.87%** |

---

## 六、XGBoost基准模型

### 6.1 模型配置
| 参数 | 值 |
|------|-----|
| n_estimators | 100 |
| max_depth | 6 |
| learning_rate | 0.1 |
| 输入维度 | 180 (30×6 flattened) |

### 6.2 评估指标
| 指标 | 值 |
|------|-----|
| MAE | 5,316 |
| RMSE | 5,860 |
| **MAPE** | **3.97%** |

---

## 七、模型对比总结

### 7.1 性能对比表
| 排名 | 模型 | 参数量 | MAE | RMSE | MAPE |
|------|------|--------|-----|------|------|
| 🥇 1 | **GRU** | 38,849 | 2,565 | 3,136 | **1.87%** |
| 🥈 2 | XGBoost | N/A | 5,316 | 5,860 | 3.97% |
| 🥉 3 | LSTM | 51,777 | 6,833 | 7,428 | 5.15% |

### 7.2 关键发现

1. **GRU表现最佳**
   - MAPE仅1.87%，显著优于其他模型
   - 参数量比LSTM少25%，训练更快
   - 在小数据集上泛化能力更强

2. **XGBoost优于LSTM**
   - 传统机器学习方法在此数据集表现不俗
   - 说明数据特征明显，非深度学习方法也能有效捕获

3. **LSTM过拟合倾向**
   - 参数量最多，但测试效果最差
   - 可能对训练数据过拟合

4. **所有模型MAPE < 10%**
   - 均达到可接受的预测精度
   - 特征工程（周期编码+周末标识）效果明显

---

## 八、可视化输出

本次分析生成了8张图表：

| 编号 | 文件名 | 描述 |
|------|--------|------|
| 05 | lstm_training_loss.png | LSTM训练/验证损失曲线 |
| 06 | gru_training_loss.png | GRU训练/验证损失曲线 |
| 07 | lstm_forecast.png | LSTM预测结果图 |
| 08 | gru_forecast.png | GRU预测结果图 |
| 09 | all_models_comparison.png | 所有模型折线对比图 |
| 10 | bar_comparison.png | 柱状图对比 |
| 11 | error_analysis.png | LSTM/GRU误差分析 |
| 12 | mape_comparison.png | MAPE排名对比图 |

---

## 九、结论与建议

### 9.1 结论
1. **GRU是最佳选择**：在本数据集上，GRU以1.87%的MAPE显著优于LSTM和XGBoost
2. **简化架构更有效**：GRU用更少的参数（38,849 vs 51,777）取得更好效果
3. **特征工程关键**：周期性编码和周末标识对提升预测精度至关重要

### 9.2 未来改进方向
1. 增加更多时间特征（节假日、天气等）
2. 尝试Transformer架构
3. 集成多模型进行预测
4. 扩大测试集以获得更稳健的评估

---

## 十、代码文件

| 文件 | 描述 |
|------|------|
| deep_learning_models.py | 主程序：LSTM、GRU、XGBoost训练与预测 |
| task1_data_preparation.py | 数据预处理 |
| data/model_comparison.csv | 模型性能对比数据 |
| data/all_predictions.csv | 所有预测结果 |
| data/lstm_model.pth | 保存的LSTM模型 |
| data/gru_model.pth | 保存的GRU模型 |

---

*报告生成日期: 2025年12月*
