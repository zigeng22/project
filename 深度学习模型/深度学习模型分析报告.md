# 深度学习模型分析报告

## STAT8003 Time Series Forecasting Course Project
### 香港机场旅客流量预测 - 深度学习部分

---

## 一、项目概述

### 1.1 研究背景
本项目使用深度学习方法对香港机场日客流量进行时间序列预测。本报告聚焦于机器学习/深度学习部分，传统时间序列方法（如SARIMA）由队友完成。

### 1.2 数据集信息
| 项目 | 描述 |
|------|------|
| 训练集 | 1,077天 (2023-01-01 至 2025-12-12) |
| 测试集 | 5天 (2025-12-13 至 2025-12-17) |
| 预测变量 | 每日旅客总数 (Total) |

### 1.3 测试集详情
| 日期 | 星期 | 类型 | 实际客流 |
|------|------|------|----------|
| 2025-12-13 | 周六 | 周末 | 138,454 |
| 2025-12-14 | 周日 | 周末 | 144,818 |
| 2025-12-15 | 周一 | 工作日 | 140,572 |
| 2025-12-16 | 周二 | 工作日 | 124,901 |
| 2025-12-17 | 周三 | 工作日 | 131,212 |

---

## 二、模型选择

本研究选择了3个模型进行对比分析：

| 模型 | 类型 | 选择理由 |
|------|------|----------|
| **Bidirectional LSTM** | 深度学习 | 双向处理序列，能够同时捕获前向和后向的时间依赖 |
| **GRU** | 深度学习 | LSTM的简化版本，门控更少，在小数据集上泛化能力强 |
| **XGBoost** | 机器学习 | 作为基准对比，代表传统ML方法的最佳水平 |

---

## 三、特征工程

### 3.1 输入特征（6维）
```
1. Total         - 历史客流量
2. DayOfWeek_sin - 星期的正弦编码
3. DayOfWeek_cos - 星期的余弦编码
4. IsWeekend     - 是否周末（0或1）
5. Month_sin     - 月份的正弦编码
6. Month_cos     - 月份的余弦编码
```

### 3.2 周期性编码说明
使用三角函数编码可以：
- 保持周期性特征的连续性（如周日→周一的过渡）
- 避免模型将星期/月份误解为数值大小关系

公式：
- `DayOfWeek_sin = sin(2π × DayOfWeek / 7)`
- `DayOfWeek_cos = cos(2π × DayOfWeek / 7)`

---

## 四、Bidirectional LSTM模型详解

### 4.1 模型架构
```
┌─────────────────────────────────────────────────────────┐
│  Input: (batch, 30, 6)                                  │
│    ↓                                                    │
│  Bidirectional LSTM: 32 hidden units (×2 directions)   │
│    ↓                                                    │
│  Concatenate: 32×2 = 64 features                       │
│    ↓                                                    │
│  Fully Connected: 64 → 1                               │
│    ↓                                                    │
│  Output: (batch, 1)                                     │
└─────────────────────────────────────────────────────────┘
```

### 4.2 Bidirectional LSTM原理
双向LSTM同时从两个方向处理序列：
- **前向LSTM**: 从t=1到t=T顺序处理
- **后向LSTM**: 从t=T到t=1逆序处理
- **输出**: 将两个方向的隐藏状态拼接

**优势**：
- 能够利用未来上下文信息
- 对于时间序列中的周期性模式捕捉更准确

### 4.3 LSTM Cell门控机制
| 门控 | 功能 |
|------|------|
| 遗忘门 (Forget Gate) | 决定丢弃哪些旧信息 |
| 输入门 (Input Gate) | 决定存储哪些新信息 |
| 输出门 (Output Gate) | 决定输出什么信息 |

### 4.4 训练配置
| 参数 | 值 |
|------|-----|
| 窗口大小 | 30天 |
| 隐藏层单元数 | 32 (每个方向) |
| LSTM层数 | 1 (双向) |
| 优化器 | Adam |
| 学习率 | 0.001 |
| 批大小 | 32 |
| 早停耐心值 | 15 |
| 训练轮次 | 3次取最佳 |
| **总参数量** | **10,305** |

### 4.5 预测结果
| 日期 | 星期 | 实际值 | 预测值 | 误差 | 误差% |
|------|------|--------|--------|------|-------|
| 12/13 | Sat | 138,454 | 140,347 | -1,893 | -1.4% |
| 12/14 | Sun | 144,818 | 144,260 | +558 | +0.4% |
| 12/15 | Mon | 140,572 | 138,315 | +2,257 | +1.6% |
| 12/16 | Tue | 124,901 | 128,353 | -3,452 | -2.8% |
| 12/17 | Wed | 131,212 | 127,632 | +3,580 | +2.7% |

### 4.6 BiLSTM评估指标
| 指标 | 值 |
|------|-----|
| MAE | 2,348 |
| RMSE | 2,597 |
| **MAPE** | **1.77%** |

---

## 五、GRU模型详解

### 5.1 模型架构
```
┌─────────────────────────────────────────────────────────┐
│  Input: (batch, 30, 6)                                  │
│    ↓                                                    │
│  GRU Layer 1: 64 hidden units                          │
│    ↓                                                    │
│  Dropout: 0.2                                          │
│    ↓                                                    │
│  GRU Layer 2: 64 hidden units                          │
│    ↓                                                    │
│  Fully Connected: 64 → 1                               │
│    ↓                                                    │
│  Output: (batch, 1)                                     │
└─────────────────────────────────────────────────────────┘
```

### 5.2 GRU原理
GRU（Gated Recurrent Unit）是LSTM的简化版本，只有两个门控：

| 门控 | 功能 |
|------|------|
| 重置门 (Reset Gate) | 决定忽略多少过去的信息 |
| 更新门 (Update Gate) | 决定使用多少候选状态 |

### 5.3 GRU vs BiLSTM对比
| 特性 | BiLSTM | GRU |
|------|--------|-----|
| 门控数量 | 3 | 2 |
| 双向处理 | ✓ | ✗ |
| 细胞状态 | 有 | 无 |
| 参数量 | 10,305 | 38,849 |
| 架构 | 1层双向 | 2层单向 |

### 5.4 训练配置
| 参数 | 值 |
|------|-----|
| 窗口大小 | 30天 |
| 隐藏层单元数 | 64 |
| GRU层数 | 2 |
| Dropout | 0.2 |
| 训练轮次 | 3次取最佳 |
| **总参数量** | **38,849** |

### 5.5 预测结果
| 日期 | 星期 | 实际值 | 预测值 | 误差 | 误差% |
|------|------|--------|--------|------|-------|
| 12/13 | Sat | 138,454 | 140,540 | -2,086 | -1.5% |
| 12/14 | Sun | 144,818 | 145,979 | -1,161 | -0.8% |
| 12/15 | Mon | 140,572 | 138,491 | +2,081 | +1.5% |
| 12/16 | Tue | 124,901 | 126,791 | -1,890 | -1.5% |
| 12/17 | Wed | 131,212 | 133,289 | -2,077 | -1.6% |

### 5.6 GRU评估指标
| 指标 | 值 |
|------|-----|
| MAE | 1,859 |
| RMSE | 1,893 |
| **MAPE** | **1.38%** |

---

## 六、XGBoost基准模型

### 6.1 模型配置
| 参数 | 值 |
|------|-----|
| n_estimators | 100 |
| max_depth | 6 |
| learning_rate | 0.1 |
| 输入维度 | 180 (30×6 flattened) |

### 6.2 评估指标
| 指标 | 值 |
|------|-----|
| MAE | 5,316 |
| RMSE | 5,860 |
| **MAPE** | **3.97%** |

---

## 七、模型对比总结

### 7.1 性能对比表
| 排名 | 模型 | 参数量 | MAE | RMSE | MAPE |
|------|------|--------|-----|------|------|
| 🥇 1 | **GRU** | 38,849 | 1,859 | 1,893 | **1.38%** |
| 🥈 2 | BiLSTM | 10,305 | 2,348 | 2,597 | 1.77% |
| 🥉 3 | XGBoost | N/A | 5,316 | 5,860 | 3.97% |

### 7.2 排名分析

**当前排名符合预期：**

| 对比 | 结果 | 分析 |
|------|------|------|
| GRU vs BiLSTM | GRU略优 | GRU参数更多(38K vs 10K)，拟合能力更强 |
| BiLSTM vs XGBoost | BiLSTM显著优 | 深度学习捕获时序依赖的能力更强 |
| 深度学习 vs 传统ML | DL胜出 | 符合预期，DL在时序预测上优势明显 |

### 7.3 关键发现

1. **深度学习显著优于传统机器学习**
   - GRU: 1.38% vs XGBoost: 3.97%（提升65%）
   - BiLSTM: 1.77% vs XGBoost: 3.97%（提升55%）

2. **GRU表现最佳**
   - MAPE仅1.38%，所有预测误差均在±2%以内
   - 2层架构+64隐藏单元配置效果最优

3. **BiLSTM参数效率高**
   - 仅10,305参数实现1.77% MAPE
   - 双向结构有效利用了序列的前后信息

4. **所有模型MAPE < 5%**
   - 均达到优秀的预测精度
   - 特征工程（周期编码+周末标识）贡献显著

---

## 八、可视化输出

本次分析生成了8张图表：

| 编号 | 文件名 | 描述 |
|------|--------|------|
| 05 | lstm_training_loss.png | BiLSTM训练/验证损失曲线 |
| 06 | gru_training_loss.png | GRU训练/验证损失曲线 |
| 07 | lstm_forecast.png | BiLSTM预测结果图 |
| 08 | gru_forecast.png | GRU预测结果图 |
| 09 | all_models_comparison.png | 所有模型折线对比图 |
| 10 | bar_comparison.png | 柱状图对比 |
| 11 | error_analysis.png | BiLSTM/GRU误差分析 |
| 12 | mape_comparison.png | MAPE排名对比图 |

---

## 九、结论与建议

### 9.1 结论
1. **GRU是最佳选择**：在本数据集上，GRU以1.38%的MAPE取得最佳效果
2. **深度学习优势明显**：BiLSTM和GRU均显著优于XGBoost
3. **特征工程关键**：周期性编码和周末标识对提升预测精度至关重要

### 9.2 未来改进方向
1. 增加更多时间特征（节假日、天气、航班信息等）
2. 尝试Attention机制或Transformer架构（需更大数据集）
3. 集成多模型进行预测
4. 扩大测试集以获得更稳健的评估

---

## 十、代码文件

| 文件 | 描述 |
|------|------|
| deep_learning_models.py | 主程序：BiLSTM、GRU、XGBoost训练与预测 |
| task1_data_preparation.py | 数据预处理 |
| data/model_comparison.csv | 模型性能对比数据 |
| data/all_predictions.csv | 所有预测结果 |
| data/lstm_model.pth | 保存的BiLSTM模型 |
| data/gru_model.pth | 保存的GRU模型 |

---

*报告生成日期: 2025年12月*
