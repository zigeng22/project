"""
é¦™æ¸¯æ”¿åºœæ•°æ®é›†å…¨é¢æ¢ç´¢ - å¯»æ‰¾é€‚åˆæ—¶é—´åºåˆ—åˆ†æçš„æ•°æ®
"""
import requests
import json
from collections import defaultdict

BASE_URL = "https://app.data.gov.hk/v1/historical-archive/list-files"

def query_api(start, end, **kwargs):
    """è°ƒç”¨API"""
    params = {"start": start, "end": end, "max": kwargs.get("max", 500)}
    for key in ["category", "provider", "format", "search"]:
        if key in kwargs and kwargs[key]:
            params[key] = kwargs[key]
    
    try:
        response = requests.get(BASE_URL, params=params, timeout=60)
        if response.status_code == 200:
            return response.json()
    except Exception as e:
        print(f"Error: {e}")
    return None

def explore_provider(provider_id, provider_name):
    """æ¢ç´¢ç‰¹å®šæ•°æ®æä¾›è€…çš„æ•°æ®"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {provider_name} ({provider_id})")
    print('='*80)
    
    result = query_api("20180101", "20241231", provider=provider_id, max=1000)
    
    if not result or "files" not in result:
        print("  æ— æ•°æ®")
        return []
    
    files = result["files"]
    total = result.get("file-count", len(files))
    print(f"æ€»å…±æœ‰ {total} ä¸ªæ–‡ä»¶\n")
    
    # æŒ‰æ•°æ®é›†åˆ†ç»„
    datasets = defaultdict(lambda: {
        "name_en": "", "name_tc": "", "files": [], 
        "formats": set(), "has_all_year": False, "sample_url": ""
    })
    
    for f in files:
        ds_id = f.get("dataset-id", "unknown")
        datasets[ds_id]["name_en"] = f.get("dataset-name-en", "")
        datasets[ds_id]["name_tc"] = f.get("dataset-name-tc", "")
        datasets[ds_id]["files"].append(f)
        datasets[ds_id]["formats"].add(f.get("format", ""))
        
        url = f.get("url", "")
        resource = f.get("resource-name-en", "")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¨éƒ¨å¹´ä»½çš„æ•°æ®
        if "ALL" in url or "all year" in resource.lower():
            datasets[ds_id]["has_all_year"] = True
            datasets[ds_id]["sample_url"] = url
        elif not datasets[ds_id]["sample_url"]:
            datasets[ds_id]["sample_url"] = url
    
    # æ•´ç†å¹¶æ˜¾ç¤ºæ•°æ®é›†
    dataset_list = []
    for ds_id, info in sorted(datasets.items(), key=lambda x: len(x[1]["files"]), reverse=True):
        dataset_list.append({
            "id": ds_id,
            "name_tc": info["name_tc"],
            "name_en": info["name_en"],
            "file_count": len(info["files"]),
            "formats": list(info["formats"]),
            "has_all_year": info["has_all_year"],
            "sample_url": info["sample_url"]
        })
        
        # æ˜¾ç¤ºä¿¡æ¯
        all_year_mark = "âœ… æœ‰å…¨éƒ¨å¹´ä»½æ•°æ®" if info["has_all_year"] else ""
        print(f"ğŸ“ {info['name_tc']} / {info['name_en']}")
        print(f"   ID: {ds_id}")
        print(f"   æ–‡ä»¶æ•°: {len(info['files'])}, æ ¼å¼: {info['formats']} {all_year_mark}")
        print(f"   ç¤ºä¾‹URL: {info['sample_url'][:80]}..." if len(info['sample_url']) > 80 else f"   ç¤ºä¾‹URL: {info['sample_url']}")
        print()
    
    return dataset_list

def check_data_sample(url):
    """æ£€æŸ¥æ•°æ®æ ·æœ¬"""
    try:
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            content = response.text
            lines = content.strip().split('\n')
            print(f"  è¡Œæ•°: {len(lines)}")
            print(f"  å‰3è¡Œ:")
            for line in lines[:3]:
                print(f"    {line[:100]}...")
            return len(lines)
    except Exception as e:
        print(f"  Error: {e}")
    return 0

def main():
    print("=" * 80)
    print("é¦™æ¸¯æ”¿åºœæ•°æ®é›†æ¢ç´¢ - å¯»æ‰¾é€‚åˆæ—¶é—´åºåˆ—é¡¹ç›®çš„æ•°æ®")
    print("=" * 80)
    
    # é‡ç‚¹æ¢ç´¢çš„æ•°æ®æä¾›è€…
    providers = [
        ("hk-hko", "é¦™æ¸¯å¤©æ–‡å°"),
        ("hk-td", "è¿è¾“ç½²"),
        ("mtr", "é¦™æ¸¯é“è·¯æœ‰é™å…¬å¸"),
        ("hk-epd", "ç¯å¢ƒä¿æŠ¤ç½²"),
        ("hk-censtatd", "æ”¿åºœç»Ÿè®¡å¤„"),
    ]
    
    all_datasets = {}
    
    for provider_id, provider_name in providers:
        datasets = explore_provider(provider_id, provider_name)
        all_datasets[provider_id] = datasets
    
    # æ€»ç»“æ¨è
    print("\n" + "=" * 80)
    print("ğŸŒŸ æ¨èæ•°æ®é›†æ€»ç»“ (é€‚åˆæ—¶é—´åºåˆ—åˆ†æ)")
    print("=" * 80)
    
    recommendations = []
    
    for provider_id, datasets in all_datasets.items():
        for ds in datasets:
            if ds["has_all_year"] and ds["file_count"] >= 5:
                recommendations.append(ds)
    
    # æŒ‰æ–‡ä»¶æ•°é‡æ’åº
    recommendations.sort(key=lambda x: x["file_count"], reverse=True)
    
    print("\nä»¥ä¸‹æ•°æ®é›†æœ‰'å…¨éƒ¨å¹´ä»½'æ•°æ®ï¼Œé€‚åˆåšæ—¶é—´åºåˆ—åˆ†æ:\n")
    for i, ds in enumerate(recommendations[:20], 1):
        print(f"{i}. {ds['name_tc']} / {ds['name_en']}")
        print(f"   æ–‡ä»¶æ•°: {ds['file_count']}, æ ¼å¼: {ds['formats']}")
        print(f"   URL: {ds['sample_url']}")
        print()
    
    return recommendations

if __name__ == "__main__":
    recommendations = main()
