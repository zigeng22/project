import requests
import pandas as pd
from io import StringIO

print("="*90)
print("é¦™æ¸¯éå¤©æ°”ç±»æ—¶é—´åºåˆ—æ•°æ®é›†è¯¦ç»†åˆ†æ")
print("="*90)

datasets_to_check = [
    ('å…¥å¢ƒå¤„-æ¯æ—¥è¿‡å¢ƒæ—…å®¢ç»Ÿè®¡', 'https://www.immd.gov.hk/opendata/eng/transport/immigration_clearance/statistics_on_daily_passenger_traffic.csv'),
    ('æœºç”µç½²-ç”µåŠ›ç»Ÿè®¡', 'https://data.gov.hk/tc-data/dataset/hk-emsd-emsd1-electricity-consumption-hongkong'),
]

# 1. å…¥å¢ƒå¤„æ•°æ®
print("\n" + "="*90)
print("ğŸ›‚ å…¥å¢ƒå¤„ - æ¯æ—¥è¿‡å¢ƒæ—…å®¢ç»Ÿè®¡")
print("="*90)
url = 'https://www.immd.gov.hk/opendata/eng/transport/immigration_clearance/statistics_on_daily_passenger_traffic.csv'
response = requests.get(url, timeout=30)
df = pd.read_csv(StringIO(response.text))

# æ¸…ç†åˆ—å
df.columns = ['Date', 'Control_Point', 'Direction', 'HK_Residents', 'Mainland_Visitors', 
              'Other_Visitors', 'Total', 'Control_Point_CN']

# è½¬æ¢æ—¥æœŸ
df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')

print(f"æ€»è¡Œæ•°: {len(df):,}")
print(f"æ—¥æœŸèŒƒå›´: {df['Date'].min().strftime('%Y-%m-%d')} åˆ° {df['Date'].max().strftime('%Y-%m-%d')}")
print(f"æ—¶é—´è·¨åº¦: {(df['Date'].max() - df['Date'].min()).days / 365.25:.1f} å¹´")
print(f"\nå£å²¸åˆ—è¡¨:")
for cp in df['Control_Point'].unique():
    print(f"  - {cp}")

print(f"\næ–¹å‘: {df['Direction'].unique().tolist()}")

# æŒ‰æ—¥æœŸæ±‡æ€»æ€»å®¢æµ
daily_total = df.groupby('Date')['Total'].sum().reset_index()
print(f"\næŒ‰æ—¥æ±‡æ€»åè¡Œæ•°: {len(daily_total):,}")
print(f"æ¯æ—¥æ€»å®¢æµç»Ÿè®¡: min={daily_total['Total'].min():,.0f}, max={daily_total['Total'].max():,.0f}, mean={daily_total['Total'].mean():,.0f}")

# å¯ä»¥æŒ‰å£å²¸åˆ†æ
print("\nå„å£å²¸æ•°æ®é‡:")
for cp in df['Control_Point'].unique()[:5]:
    cp_data = df[df['Control_Point'] == cp]
    cp_daily = cp_data.groupby('Date')['Total'].sum()
    print(f"  {cp}: {len(cp_daily)} å¤©æ•°æ®")

# 2. æ¢ç´¢data.gov.hkçš„å…¶ä»–æ•°æ®é›†
print("\n" + "="*90)
print("ğŸ” æ¢ç´¢ data.gov.hk å…¶ä»–å¼€æ”¾æ•°æ®")
print("="*90)

other_urls = [
    ('è‚¡ç¥¨æ¯æ—¥æˆäº¤', 'https://www.hkex.com.hk/-/media/HKEX-Market/Market-Data/Statistics/Consolidated-Reports/Annual-Market-Statistics/2023-statistics.xlsx'),
    ('ç©ºæ°”è´¨é‡-ä¸€èˆ¬ç›‘æµ‹ç«™', 'https://cd.epic.epd.gov.hk/EPICDI/air/download/?lang=en'),
]

# 3. ç¯ä¿ç½²ç©ºæ°”è´¨é‡æ•°æ®
print("\n" + "="*90) 
print("ğŸŒ«ï¸ ç¯ä¿ç½² - ç©ºæ°”è´¨é‡æ•°æ®")
print("="*90)
# ç©ºæ°”è´¨é‡æ•°æ®URLæ ¼å¼
aqhi_url = 'https://www.aqhi.gov.hk/epd/ddata/html/out/24aqhi_Eng.csv'
try:
    response = requests.get(aqhi_url, timeout=30)
    if response.status_code == 200:
        print(f"ç©ºæ°”è´¨é‡å®æ—¶æ•°æ®å¯ç”¨")
        print(f"å†…å®¹é¢„è§ˆ:\n{response.text[:500]}")
except Exception as e:
    print(f"Error: {e}")

# 4. å¤©æ–‡å°çš„å…¶ä»–æœ‰è¶£æ•°æ®
print("\n" + "="*90)
print("ğŸŒŠ å¤©æ–‡å° - æ½®æ±æ•°æ® (éæ¸©åº¦)")
print("="*90)
tide_url = 'https://data.weather.gov.hk/weatherAPI/opendata/opendata.php?dataType=HHOT&lang=en&rformat=csv'
try:
    response = requests.get(tide_url, timeout=30)
    if response.status_code == 200:
        print(f"æ½®æ±æ•°æ®å¯ç”¨")
        lines = response.text.split('\n')[:10]
        for line in lines:
            print(f"  {line}")
except Exception as e:
    print(f"Error: {e}")
